#+title: ob-llm

* ob-llm
org-babel integration for llm's using the ~llm~ backend.

Example config.
When you define the providers in the ~use-package llm~ block and then put ~:after  llm~ in the
use-package block for other packages that use this package. you get to use those providers in both packages.

Here is an example with ~llm~, ~ellama~ and ~ob-llm~.

#+begin_src emacs-lisp
(use-package! llm
  :config
  (let* ((haiku (make-llm-claude
                 :key (getenv "ANTHROPIC_API_KEY")
                 :chat-model "claude-3-5-haiku-latest"))
         (sonnet (make-llm-claude
                  :key (getenv "ANTHROPIC_API_KEY")
                  :chat-model "claude-3-5-sonnet-latest"))
         (opus (make-llm-claude
                :key (getenv "ANTHROPIC_API_KEY")
                :chat-model "claude-3-opus-20240229"))
         (qwen (make-llm-ollama
                :chat-model "qwen2.5-coder:3b"
                :embedding-model "qwen2.5-coder:3b"))
         (zephyr (make-llm-ollama
                  :chat-model "zephyr:latest"
                  :embedding-model "zephyr:latest"))
         (llama (make-llm-ollama
                 :chat-model "llama3.2:1b"
                 :embedding-model "nomic-embed-text"
                 :default-chat-non-standard-params '(("num_ctx" . 8192)))))
    (setq llm-providers
          `(("llama" . ,llama)
            ("zephyr" . ,zephyr)
            ("qwen" . ,qwen)
            ("sonnet" . ,sonnet)
            ("opus" . ,opus)
            ("haiku" . ,haiku)))))

(use-package! ellama
  :after llm
  :config
  (setq ellama-naming-scheme #'ellama-extras-generate-name-by-llm
        ellama-provider (alist-get "haiku" llm-providers nil nil #'string=)
        ellama-providers llm-providers
        ellama-naming-provider (alist-get "haiku" llm-providers nil nil #'string=)
        ellama-translation-provider (alist-get "opus" llm-providers nil nil #'string=))
  (map! :map ellama-command-map
        (:leader
         :prefix ("e" . "ellama")
         :desc "Toggle prompt debugging" "dp" #'ellama-extras-toggle-debug
         (:prefix ("a" . "ask")
          :desc "Ask about" "a" #'ellama-ask-about
          :desc "Chat" "i" #'ellama-chat
          :desc "Ask in new session" "n" #'ellama-extras-ask-new
          :desc "Asking in new `thinking` session" "T" #'ellama-ask-thinking
          :desc "Short answers" "S" #'ellama-short-answers))))

(use-package! ob-llm
  :after (org llm)
  :config
  (setq org-babel-min-lines-for-block-output 0
        ob-llm-providers llm-providers
        ob-llm-default-provider (alist-get "haiku" llm-providers nil nil #'string=)))
#+end_src
